---
title: 'Objective 2: Experimental Models'
author: "Joseph Lazarus"
date: "5/28/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r life expectancy data}
#data is cleaned and scaled (Friday May 28th)
df <- read.csv("https://raw.githubusercontent.com/JosephLazarus/Life_Expectancy/main/Data_Folder/clean_scaled.csv", header = TRUE, fileEncoding="UTF-8-BOM")
```

Here i am checking my models.

IMPORTANT:  I have not done a split on date. Date is not present in this cleaned_scaled.csv


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
                              Train/Test Split code
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r}

set.seed(31) # prime number for good luck

sample_size = round(nrow(df)*.70) # setting what is 70%
index <- sample(seq_len(nrow(df)), size = sample_size)

training.data <- df[index, ]
testing.data <- df[-index, ]

#sanity check the split
dim(df)
dim(training.data)
dim(testing.data)


```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                             Step 3.1: Experimental Model Engine
                                       Knn Regression
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
```{r}
library(caret)
#step 1 standardize the data. This data set is pre-scaled

#K Nearest Neighbors Regression using Caret


#Tuning the Hyperparameter K
k.to.try = seq(1,20, by = 1)

train.knn <- function(mr.rogers) {
  knnreg(training.data$Life.expectancy ~ ., data = training.data, k = mr.rogers)
}

knn.list <- lapply(k.to.try, train.knn)

calc.rmse = function(actual, predicted) {
  sqrt(mean((actual - predicted)^2))
}

knn.train.predictions <- lapply(knn.list, predict, training.data)
knn.test.predictions <- lapply(knn.list, predict, testing.data)


knn.rmse.train <- sapply(knn.train.predictions, calc.rmse, actual = training.data$Life.expectancy)
knn.rmse.test <- sapply(knn.test.predictions, calc.rmse, actual = testing.data$Life.expectancy)

k.to.try[which.min(knn.rmse.test)]

plot(k.to.try, knn.rmse.test, type = "b", col = "dodgerblue", pch = 20, 
     ylim = range(c(knn.rmse.test, knn.rmse.train)), 
    xlab = "K Neighbors",
    ylab = "RMSE Specificy units (years?",
    main = "Test and Training set RMSE vs K")

lines(k.to.try, knn.rmse.train, type = "b", col = "darkorange", pch = 23)
legend("bottomright", c("Train RMSE", "Test RMSE"), 
       col = c("darkorange", "dodgerblue"),
       lty = c(1), 
       pch = c(23, 20))

# lowest looks like knn = 3

knnt3 <- knnreg(training.data$Life.expectancy ~ ., data = training.data, k=3)
data.mod.knnt3 <- data.frame(predicted = predict(knnt3), observed= training.data$Life.expectancy)

knnt3.mse <- mean((data.mod.knnt3$predicted - data.mod.knnt3$observed)^2)
knnt3.rmse <- sqrt(mean((data.mod.knnt3$predicted - data.mod.knnt3$observed)^2))

#they said it couldn't be done but I did it. plotted observed vs predicted with caret package. 
ggplot(data.mod.knnt3,                                     
       aes(x = predicted,
           y = observed)) +
  geom_point() +
  geom_abline(intercept = 0,
              slope = 1,
              color = "red",
              size = 2)
table(knnt3.mse, knnt3.rmse)

#find another knn regression model outside of caret

```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                             Step 3.2: Experimental Model Engine
                                        Tree Models
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r}
library(rpart)
library(rpart.plot)

dt.test.model <- rpart(training.data$Life.expectancy ~ ., data = training.data, method = 'anova', cp = .001)

rpart.plot(dt.test.model)

dt.model.pred = predict(dt.test.model, newdata = testing.data[,-1])

#tunning the hyperparameter CP : default 0.01
# this means that the overall R-squared must increase by cp
# luckily plotcp does this for us!

plotcp(dt.test.model)
printcp(dt.test.model)

#i like round 17 cp = .0029175
# lets discuss why

dt.model <-  rpart(training.data$Life.expectancy ~ ., data = training.data, method = 'anova', cp = 0.0029175)

rpart.plot(dt.model)

dt.model.pred <- predict(dt.model, newdata = testing.data[,-1])

dt.model.ASE = mean((testing.data[,1] - predict(dt.model, testing.data[,-1]))^2)
dt.model.RMSE = sqrt(mean((testing.data[,1] - predict(dt.model, testing.data[,-1]))^2))

data.mod.dt <- data.frame(predicted = predict(dt.model), observed= training.data$Life.expectancy)

# Draw plot using ggplot2 package this time

ggplot(data.mod.dt,                                     
       aes(x = predicted,
           y = observed)) +
  geom_point() +
  geom_abline(intercept = 0,
              slope = 1,
              color = "red",
              size = 2)


```