---
title: 'Objective 2: Experimental Models'
author: "Joseph Lazarus"
date: "5/28/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

rated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r life expectancy data}
library(ggplot2)

#data is cleaned and scaled (Friday May 31th)
df <- read.csv("https://raw.githubusercontent.com/JosephLazarus/Life_Expectancy/main/Data_Folder/clean_scaled.csv", header = TRUE, fileEncoding="UTF-8-BOM")


#removing NA's causing problems with dates. too many fields still missing
#which(is.na(df))

#still finding NAS remove them
df <- na.omit(df)


```

```{r}
library(ggthemes)
theme_set(theme_fivethirtyeight())
theme_update(axis.title = element_text()) #the default for fivethirtyeight is to not show axis labels, this removes that default so we can choose to specify and display axis titles
theme_update(plot.title = element_text(hjust = 0.5))
```




~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
                              Train/Test Split code
IMPORTANT:  I have not done a split on date. Date is not present in this cleaned_scaled.csv
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r random split}

set.seed(31) # prime number for good luck

sample_size = round(nrow(df)*.70) # setting what is 70%
index <- sample(seq_len(nrow(df)), size = sample_size)

cs.training.data <- df[index, ]
cs.testing.data <- df[-index, ]

#sanity check the split
dim(df)
dim(cs.training.data)
dim(cs.testing.data)


```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                         train/test split on Date
                    
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r Data split}
cs.training.data <- df[c(df$Year <= 2010),]
cs.testing.data <- df[c(df$Year > 2010),]

dim(df)
dim(cs.training.data)
dim(cs.testing.data)

cs.training.data <- subset(cs.training.data, select = -c(Country,Year))
cs.testing.data <- subset(cs.testing.data, select = -c(Country, Year))
```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                                 Model Metrics
                               AIC BIC RMSE MSE
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


```{r AIC BIC RMSE, MSE functions}
AIC <- function(y, y_pred, n, k){
  resids = y - y_pred
  sse = sum(resids^2)
  AIC =  n * log(sse/n) + 2*(k + 1)
  print(return(AIC))
}

BIC <- function(y, y_pred, n, k){
  resids = y - y_pred
  sse = sum(resids^2)
  BIC = n * log(sse/n) + log(n) * (k+1)
  print(return(BIC))
}

calc.rmse <- function(actual, predicted){
  sqrt(mean(actual - predicted)^2)
}

#create function for MSE / ASE
calc.ase <- function(actual, predicted){
  (mean(actual - predicted)^2)
}

```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                             Step 3.1: Experimental Model Engine
                                       Knn Regression
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r knn regression with caret}
library(caret)
library(plyr)
library(lattice)
knn2 <- knnreg(cs.training.data$Life.expectancy ~ ., data = cs.training.data, k=2)

train.knn = function(mr.rogers){
  knnreg(cs.training.data$Life.expectancy ~., data = cs.training.data, k=mr.rogers)
} 

test.knn =  function(mr.rogers){
  knnreg(cs.testing.data$Life.expectancy ~., data = cs.testing.data, k=mr.rogers)
} 

k.to.try <- seq(1,50, by = 1)
#create and store list knn predictions for k = 1 thru fiddy
knn.list.train = lapply(k.to.try, train.knn)
knn.list.test = lapply(k.to.try, test.knn)


#create and store list of predictions
knn.train.predictions <- lapply(knn.list.train, predict, cs.training.data)
knn.test.predictions <- lapply(knn.list.test, predict, cs.testing.data)
```

Model Metrics RMSE
```{r Root Mean Square Error}
#create function for RMSE


#create and store matrix of RMSE
knn.rmse.train <- sapply(knn.train.predictions, calc.rmse, actual = cs.training.data$Life.expectancy)
knn.rmse.test <- sapply(knn.test.predictions, calc.rmse, actual = cs.testing.data$Life.expectancy)

#RMSE plot of training vs predicted 
plot(k.to.try, knn.rmse.test, type = "b", col = "dodgerblue", pch = 20, 
     ylim = range(c(knn.rmse.test, knn.rmse.train)),
     xlab = "K Neighbors",
    ylab = "RMSE Specificy units (years?",
    main = "Test and Training RMSE vs K")
lines(k.to.try, knn.rmse.train, type = "b", col = "darkorange", pch = 23)
index<-which(knn.rmse.test ==min(knn.rmse.test))
points(index,knn.ase.test[index],col="red",pch=10)
legend("topright", c("Train RMSE", "Test RMSE"), 
       col = c("darkorange", "dodgerblue"),
       lty = c(1), 
       pch = c(23, 20))
grid()
```

model Metrics ASE
```{r ASE}

#create and store matrix of RMSE
knn.ase.train <- sapply(knn.train.predictions, calc.ase, actual = cs.training.data$Life.expectancy)
knn.ase.test <- sapply(knn.test.predictions, calc.ase, actual = cs.testing.data$Life.expectancy)

plot(k.to.try, knn.ase.test, type = "b", col = "dodgerblue", pch = 20, 
     ylim = range(c(knn.ase.test, knn.rmse.train)),
     xlab = "K Neighbors",
    ylab = "ASE",
    main = "Test and Training ASE vs K")
lines(k.to.try, knn.ase.train, type = "b", col = "darkorange", pch = 23)
index<-which(knn.ase.test ==min(knn.ase.test))
points(index,knn.ase.test[index],col="red",pch=10)
legend("topright", c("Train ASE", "Test ASE"), 
       col = c("darkorange", "dodgerblue"),
       lty = c(1), 
       pch = c(23, 20))
grid()



```

```{r f-ing ggplot}
#~~~~~~~~~~~~~~~~~~F you ggplot~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#knnValues <- c(1:50)
#knn.rmse.train <-ldply(knn.train.predictions, calc.rmse, actual = cs.training.data$Life.expectancy)
#knn.rmse.test <- ldply(knn.test.predictions, calc.rmse, actual = cs.testing.data$Life.expectancy)

#df.rmse = as.data.frame(cbind(knnValues, knn.rmse.train , knn.rmse.test))

#colnames(df.rmse) <- c('k_value','RMSE_train','RMSE_test')

#ggplot(data = df.rmse, aes(x=k_value)) +
#  geom_line(aes(y=RMSE_train), color = "darkred") +
#  geom_line(aes(y=RMSE_test), color = "steelblue") +
#  labs(title = "RMSE of training vs Test Set" , x= "Value of K", y = 'RMSE') +
#  theme(legend.position = "botoom")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



```

Model Diagnostics
```{r predicted vs expected}

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#removing country column from the data. 
#maybe set it to factor instead?

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


# lowest looks like knn = 38

# x = data frame of training set predictors
# y = numeric vector of outcomes
knnt3 <- knnreg(x= cs.training.data[,-1], y=cs.training.data[,1], k=1)

#predict(knnt3, newdata = cs.testing.data[,-1])

#data frame of predicted vs expected
data.mod.knnt3 <- data.frame(predicted = predict(knnt3, newdata = cs.testing.data[-1]), observed= cs.testing.data[,1])

knnt3.mse <- round(mean((data.mod.knnt3$predicted - data.mod.knnt3$observed)^2), digits = 3)
knnt3.rmse <- round(sqrt(mean((data.mod.knnt3$predicted - data.mod.knnt3$observed)^2)), digits = 3)





table(knnt3.mse, knnt3.rmse)



```

```{r AIC & BIC knn}


knn.38AIC <- AIC(data.mod.knnt3$observed, data.mod.knnt3$predicted, nrow(data.mod.knnt3), 21)

knn.38BIC <- BIC(data.mod.knnt3$observed, data.mod.knnt3$predicted, nrow(data.mod.knnt3), 21)

knn.1AIC <- AIC(data.mod.knnt3$observed, data.mod.knnt3$predicted, nrow(data.mod.knnt3), 21)
knn.1BIC <- BIC(data.mod.knnt3$observed, data.mod.knnt3$predicted, nrow(data.mod.knnt3), 21)

table(knn.38AIC, knn.38BIC, knn.1AIC,knn.1BIC)
```

```{r knn predicted vs expected}

#they said it couldn't be done but I did it. plotted observed vs predicted with caret package. 
ggplot(data.mod.knnt3,                                     
       aes(x = predicted,
           y = observed)) +
  geom_point() +
  geom_abline(intercept = 0,
              slope = 1,
              color = "red",
              size = 2)

```

```{r knn with selected variables}


```

```{r}

#find another knn regression model outside of caret
#install.packages("FNN", dependencies = TRUE, INSTALL_opts = '--no-lock')
library(FNN)
```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                             Step 3.2: Experimental Model Engine
                                        Tree Models
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r}
library(rpart)
library(rpart.plot)



dt.test.model <- rpart(cs.training.data$Life.expectancy ~ ., data = cs.training.data, method = 'anova', cp = .001)

rpart.plot(dt.test.model)

dt.model.pred = predict(dt.test.model, newdata = cs.testing.data[,-1])
```

```{r tunning DT model}
#tunning the hyperparameter CP : default 0.01
# this means that the overall R-squared must increase by cp
# luckily plotcp does this for us!

plotcp(dt.test.model)
printcp(dt.test.model)

#i like round 17 cp = .0029175
# lets discuss why

dt.model <-  rpart(cs.training.data$Life.expectancy ~ ., data = cs.training.data, method = 'anova', cp = 0.007)

rpart.plot(dt.model)

dt.model.pred <- predict(dt.model, newdata = cs.testing.data[,-1], cp = 0.007)

dt.model.ASE = mean((cs.testing.data[,1] - predict(dt.model, cs.testing.data[,-1]))^2)
dt.model.RMSE = sqrt(mean((cs.testing.data[,1] - predict(dt.model, cs.testing.data[,-1]))^2))

data.mod.dt <- data.frame(predicted = predict(dt.model), observed= cs.training.data$Life.expectancy)

summary(dt.model)



# Draw plot using ggplot2 package this time
```

```{r AIC decesion tree}

AIC(data.mod.dt$observed, data.mod.dt$predicted,nrow(data.mod.dt) ,19)
BIC(data.mod.dt$observed, data.mod.dt$predicted,nrow(data.mod.dt) ,19)
```

```{r DT model Expected Vs predicted}
ggplot(data.mod.dt,                                     
       aes(x = predicted,
           y = observed)) +
  geom_point() +
  geom_abline(intercept = 0,
              slope = 1,
              color = "red",
              size = 2)

```

```{r lasso with glmnet}

library(glmnet)



x = model.matrix(cs.training.data$Life.expectancy ~ . ,cs.training.data)[,-1]
y = cs.training.data$Life.expectancy

xtest<-model.matrix(cs.testing.data$Life.expectancy~.,cs.testing.data)[,-1]
ytest<-(cs.testing.data$Life.expectancy)

grid=10^seq(10,-2, length =100)
lasso.mod=glmnet(x,y,alpha=1, lambda =grid)

cv.out=cv.glmnet(x,y,alpha=1) #alpha=1 performs LASSO
plot(cv.out)
bestlambda<-cv.out$lambda.min  #Optimal penalty parameter.  You can make this call visually.
lasso.pred=predict (lasso.mod ,s=bestlambda ,newx=xtest)

testMSE_LASSO<-mean((ytest-lasso.pred)^2)
testMSE_LASSO


coef(lasso.mod,s=bestlambda)

```

```{r lasso with caret}
library(dplyr)
set.seed(1234)
x <- model.matrix(Life.expectancy~.,cs.training.data)[,-1]
y <- cs.training.data$Life.expectancy
xtest <- model.matrix(Life.expectancy~.,cs.testing.data)[,-1]
ytest <- cs.testing.data$Life.expectancy
grid=10^seq(10,-2, length =100)
lasso<-train(y= y,
                 x = x,
                 method = 'glmnet', 
                 tuneGrid = expand.grid(alpha = 1, lambda = grid)
               ) 

ridge <-train(y=y, x = x, method = 'glmnet',tuneGrid = expand.grid(alpha = 0, lambda = grid))

predictions_lasso <- lasso %>% predict(xtest)
predictions_ridge <- ridge %>% predict(xtest)

Lasso_RMSE = RMSE(predictions_lasso, ytest)
Lasso_RMSE


Ridge_RMSE = RMSE(predictions_ridge, ytest)
Ridge_RMSE

#Post resample - Lasso
lasso.cs.testing.data<-postResample(pred = predictions_lasso, obs = cs.testing.data$Life.expectancy)
lasso.cs.testing.data
ridge.cs.testing.data<-postResample(pred = predictions_ridge, obs = cs.testing.data$Life.expectancy)
ridge.cs.testing.data

coef(lasso$finalMode,lasso$finalModel$lambdaOpt)
varImp(lasso)
coef(ridge$finalModel,ridge$finalModel$lambdaOpt)
varImp(ridge)

ImpLasso <- varImp(lasso)
ImpRidge <- varImp(ridge)

plot(ImpLasso)
plot(ImpRidge)

```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                         Run models Again of VarIMP
                         Filtered.Income.composition.of.resources
                         log.adj.Adult.Mortality
                         log.HIV.AIDS
                         Developed
                         log.under.five.deaths
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  filtered.Income.composition.of.resources, log.adj.Adult.Mortality, log.HIV.AIDS, Developed, log.under.five.deaths
```{r}
# function is not liking all these variables will use select to filter training set
knn5var <- knnreg(cs.training.data$Life.expectancy ~ filtered.Income.composition.of.resources, log.adj.Adult.Mortality, log.HIV.AIDS, Developed, log.under.five.deaths, data = cs.training.data, k=2)
```


```{r}

cs.5var.training.data <- subset(cs.training.data, select = c(Life.expectancy,filtered.Income.composition.of.resources, log.adj.Adult.Mortality, log.HIV.AIDS, Developed, log.under.five.deaths))
cs.5var.testing.data <- subset(cs.testing.data, select = c(Life.expectancy,filtered.Income.composition.of.resources, log.adj.Adult.Mortality, log.HIV.AIDS, Developed, log.under.five.deaths))

```


```{r}


train5var.knn = function(mr.rogers){
  knnreg(cs.5var.training.data$Life.expectancy ~ ., data = cs.5var.training.data, k=mr.rogers)
} 

test5var.knn =  function(mr.rogers){
  knnreg(cs.5var.testing.data$Life.expectancy ~ ., data = cs.5var.testing.data, k=mr.rogers)
} 

k.to.try <- seq(1,50, by = 1)
#create and store list knn predictions for k = 1 thru fiddy
knn5var.list.train = lapply(k.to.try, train5var.knn)
knn5var.list.test = lapply(k.to.try, test5var.knn)


#create and store list of predictions
knn5var.train.predictions <- lapply(knn5var.list.train, predict, cs.5var.training.data)
knn5var.test.predictions <- lapply(knn5var.list.test, predict, cs.5var.testing.data)
```

Model Metrics RMSE
```{r Root Mean Square Error}
#create function for RMSE


#create and store matrix of RMSE
knn5var.rmse.train <- sapply(knn5var.train.predictions, calc.rmse, actual = cs.5var.training.data$Life.expectancy)
knn5var.rmse.test <- sapply(knn5var.test.predictions, calc.rmse, actual = cs.5var.testing.data$Life.expectancy)

#RMSE plot of training vs predicted 
plot(k.to.try, knn5var.rmse.test, type = "b", col = "dodgerblue", pch = 20, 
     ylim = range(c(knn.rmse.test, knn.rmse.train)),
     xlab = "K Neighbors",
    ylab = "RMSE Specificy units (years?",
    main = "Test and Training RMSE vs K")
lines(k.to.try, knn5var.rmse.train, type = "b", col = "darkorange", pch = 23)
index<-which(knn5var.rmse.test ==min(knn.rmse.test))
points(index,knn5var.ase.test[index],col="red",pch=10)
legend("topright", c("Train RMSE", "Test RMSE"), 
       col = c("darkorange", "dodgerblue"),
       lty = c(1), 
       pch = c(23, 20))
grid()
```

```{r}
knn5var.ase.train <- sapply(knn5var.train.predictions, calc.ase, actual = cs.5var.training.data$Life.expectancy)
knn5var.ase.test <- sapply(knn5var.test.predictions, calc.ase, actual = cs.5var.testing.data$Life.expectancy)

plot(k.to.try, knn5var.ase.test, type = "b", col = "dodgerblue", pch = 20, 
     ylim = range(c(knn.ase.test, knn5var.rmse.train)),
     xlab = "K Neighbors",
    ylab = "ASE",
    main = "Test and Training ASE vs K")
lines(k.to.try, knn5var.ase.train, type = "b", col = "darkorange", pch = 23)
index<-which(knn5var.ase.test ==min(knn5var.ase.test))
points(index,knn5var.ase.test[index],col="red",pch=10)
legend("topright", c("Train ASE", "Test ASE"), 
       col = c("darkorange", "dodgerblue"),
       lty = c(1), 
       pch = c(23, 20))
grid()
```

```{r predicted vs expected}
knnt5var3 <- knnreg(x= cs.5var.training.data[,-1], y=cs.5var.training.data[,1], k=1)

#predict(knnt3, newdata = cs.5var.testing.data[,-1])

#data frame of predicted vs expected
data.mod5var.knnt3 <- data.frame(predicted = predict(knnt5var3, newdata = cs.5var.testing.data[-1]), observed= cs.5var.testing.data[,1])

knnt5var3.mse <- round(mean((data.mod5var.knnt3$predicted - data.mod5var.knnt3$observed)^2), digits = 3)
knnt5var3.rmse <- round(sqrt(mean((data.mod5var.knnt3$predicted - data.mod5var.knnt3$observed)^2)), digits = 3)





table(knnt5var3.mse, knnt5var3.rmse)

#they said it couldn't be done but I did it. plotted observed vs predicted with caret package. 
ggplot(data.mod5var.knnt3,                                     
       aes(x = predicted,
           y = observed)) +
  geom_point() +
  geom_abline(intercept = 0,
              slope = 1,
              color = "red",
              size = 2)

```