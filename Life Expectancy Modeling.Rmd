---
title: "Life Expectancy Modeling"
author: "Satvik, Joe, and Rick"
output: html_notebook
editor_options: 
  chunk_output_type: console
---
```{r}
library(ggthemes)
theme_set(theme_fivethirtyeight())
theme_update(axis.title = element_text()) #the default for fivethirtyeight is to not show axis labels, this removes that default so we can choose to specify and display axis titles
theme_update(plot.title = element_text(hjust = 0.5))
```

```{r import data}
#Import Clean, Scaled, and Transformed CSV 
# cst = cleaned scaled transformed
cst.df <- read.csv("https://raw.githubusercontent.com/JosephLazarus/Life_Expectancy/main/Data_Folder/clean_scaled.csv", header = TRUE, fileEncoding="UTF-8-BOM")

cst.df$Developed = as.factor(cst.df$Developed) 

#Import cleaned scaled 


#import cleaned

#Must omit values before running model
cst.df <- na.omit(cst.df)
```

```{r train test split}
#Train / Test split by Year
cst.training <- cst.df[c(cst.df$Year <= 2010),]
cst.test <- cst.df[c(cst.df$Year > 2010),]

dim(cst.df)
dim(cst.training)
dim(cst.test)

cst.training <- subset(cst.training, select = -c(Country,Year))
cst.test <- subset(cst.test, select = -c(Country, Year))
```


```{r}
c.df <- read.csv("https://raw.githubusercontent.com/JosephLazarus/Life_Expectancy/main/Data_Folder/cleaned.csv", header = TRUE, fileEncoding="UTF-8-BOM")
c.df$Developed = as.factor(c.df$Developed)
cleaned.df = subset(c.df, select = -c(Adult.Mortality))
cleaned.df = na.omit(cleaned.df)

cleaned.training <- cleaned.df[c(cleaned.df$Year <= 2010),]
cleaned.test <- cleaned.df[c(cleaned.df$Year > 2010),]

cleaned.training <- subset(cleaned.training, select = -c(Country,Year))
cleaned.test <- subset(cleaned.test, select = -c(Country, Year))

dim(c.df)
dim(cleaned.training)
#nrow = 560
dim(cleaned.test)
```

LASSO MODEL used for Analysis
```{r}
preprocessParams<-preProcess(X, method = c("center", "scale"))
X <- predict(preprocessParams, X)

X <- model.matrix(Life.expectancy~.,cleaned.training)[,-1]
y <- cleaned.training$Life.expectancy

lambdaGrid = 10^seq(10,-2, length =100)
A.Lasso<-train(y = y,
             x = X,
             method = 'glmnet',
             tuneGrid = expand.grid(alpha = 1, lambda = 1)
             )
A.Lasso

coef(A.Lasso$finalModel,A.Lasso$finalModel$lambdaOpt)


B.Lasso<-train(y = y,
             x = X,
             method = 'glmnet',
             tuneGrid = expand.grid(alpha = 1, lambda = 0.5)
             )
B.Lasso
coef(B.Lasso$finalModel,B.Lasso$finalModel$lambdaOpt)

varImp.Lasso = varImp(c.Lasso)
varImp.Lasso
plot.varImp.Lasso = plot(varImp(c.Lasso))
plot.varImp.Lasso

#Fitting Lassso Model A using 17 predictors, lambda = 1
var17.fit = lm(Life.expectancy ~ infant.deaths+Alcohol+Hepatitis.B+Measles+Total.expenditure+Diphtheria+HIV.AIDS+thinness..1.19.years+thinness.5.9.years+EstPopulation+EstGDPpercapita+CorrectedExpenditure+new.Adult.Mortality+WHO.BMI.metric+EstPolio+filtered.Income.composition.of.resources+Developed, data = cleaned.training)

fit17.preds = predict(var17.fit, newdata = cleaned.test)
rmse.var17= RMSE(fit17.preds,cleaned.test$Life.expectancy)
rmse.var17

#Function for the AIC, Run all before proceeding
AIC <- function(y, y_pred, n, k){
  resids = y - y_pred
  sse = sum(resids^2)
  AIC =  n * log(sse/n) + 2*(k + 1)
  print(return(AIC))
}
c.getdf <- function(model) {
  data.frame(predicted = predict(model, newdata = cleaned.test[-1]), observed = cleaned.test[,1])
}
#(2) use above call to get the AIC, input dataframe and number of parameters
c.aic <- function(dataframe, numparameters){
  AIC(dataframe$observed, dataframe$predicted, nrow(dataframe), numparameters)
}

#RMSE for 17 Variable Model is 2.33
rmse.var17

#AIC for 17 Variable Model is 984.219
dataframe.17 = c.getdf(var17.fit)
aic.17= c.aic(dataframe.17,17)
aic.17

#Fitting Lasso Model B using only 5 predictors lambda = 0.5
var5.fit = lm(Life.expectancy ~ thinness.5.9.years+Schooling+new.Adult.Mortality+EstPolio+filtered.Income.composition.of.resources, data = cleaned.training)
fit5.preds = predict(var5.fit, newdata = cleaned.test)
rmse.var5= RMSE(fit5.preds,cleaned.test$Life.expectancy)
rmse.var5

#AIC for 5 Variable Model is 1016.399
dataframe.5 = c.getdf(var5.fit)
aic.5= c.aic(dataframe.5,5)
#RMSE for 5 variable Model 2.451708
aic.5
```



```{r}
X <- model.matrix(Life.expectancy~.*.,cleaned.training)[,-1]

y <- cleaned.training$Life.expectancy

lambdaGrid = 10^seq(10,-2, length =100)

Lasso<-train(y = y,
             x = X,
             method = 'glmnet',
             tuneGrid = expand.grid(alpha = 1, lambda = lambdaGrid),
             na.action = na.omit
             )
Lasso$finalModel$lambdaOpt
plot(varImp(Lasso))


complex.var5.fit = lm(Life.expectancy ~ filtered.Income.composition.of.resources + thinness..1.19.years:Developed + Alcohol:Developed + new.Adult.Mortality, data = cleaned.training)
summary(complex.var5.fit)

complex.preds = predict(complex.var5.fit, newdata = cleaned.test)
complex.rmse = RMSE(complex.preds,cleaned.test$Life.expectancy)
complex.rmse

AIC <- function(y, y_pred, n, k){
  resids = y - y_pred
  sse = sum(resids^2)
  AIC =  n * log(sse/n) + 2*(k + 1)
  print(return(AIC))
}
c.getdf <- function(model) {
  data.frame(predicted = predict(model, newdata = cleaned.test[-1]), observed = cleaned.test[,1])
}
#(2) use above call to get the AIC, input dataframe and number of parameters
c.aic <- function(dataframe, numparameters){
  AIC(dataframe$observed, dataframe$predicted, nrow(dataframe), numparameters)
}
complex.var5.fit
complex.df = c.getdf(complex.var5.fit)
com.aic =  c.aic(complex.df,6)
com.aic
```


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                                 Model Metrics
                               AIC BIC RMSE MSE
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


```{r AIC BIC RMSE, MSE functions}
AIC <- function(y, y_pred, n, k){
  resids = y - y_pred
  sse = sum(resids^2)
  AIC =  n * log(sse/n) + 2*(k + 1)
  print(return(AIC))
}

BIC <- function(y, y_pred, n, k){
  resids = y - y_pred
  sse = sum(resids^2)
  BIC = n * log(sse/n) + log(n) * (k+1)
  print(return(BIC))
}

calc.rmse <- function(actual, predicted){
  sqrt(mean(actual - predicted)^2)
}

#create function for MSE / ASE
calc.ase <- function(actual, predicted){
  (mean(actual - predicted)^2)
}

```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                             Step 3.1: Experimental Model Engine
                                       Knn Regression
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r knn regression with caret}
library(caret)
library(plyr)
library(lattice)

knn2 <- knnreg(cst.training$Life.expectancy ~ ., data = cst.training, k=2)

train.knn = function(mr.rogers){
  knnreg(cst.training$Life.expectancy ~., data = cst.training, k=mr.rogers)
} 

test.knn =  function(mr.rogers){
  knnreg(cs.test$Life.expectancy ~., data = cs.testing.data, k=mr.rogers)
} 

k.to.try <- seq(1,50, by = 1)
#create and store list knn predictions for k = 1 thru fiddy
knn.list.train = lapply(k.to.try, train.knn)
knn.list.test = lapply(k.to.try, test.knn)


#create and store list of predictions
knn.train.predictions <- lapply(knn.list.train, predict, cst.training)
knn.test.predictions <- lapply(knn.list.test, predict, cs.testing.data)
```

