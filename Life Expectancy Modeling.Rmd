---
title: "Life Expectancy Modeling"
author: "Satvik, Joe, and Rick"
output: html_notebook
editor_options: 
  chunk_output_type: console
---
```{r}
library(ggthemes)
theme_set(theme_fivethirtyeight())
theme_update(axis.title = element_text()) #the default for fivethirtyeight is to not show axis labels, this removes that default so we can choose to specify and display axis titles
theme_update(plot.title = element_text(hjust = 0.5))
```

```{r import data}
#Import Clean, Scaled, and Transformed CSV 
# cst = cleaned scaled transformed
cst.df <- read.csv("https://raw.githubusercontent.com/JosephLazarus/Life_Expectancy/main/Data_Folder/clean_scaled.csv", header = TRUE, fileEncoding="UTF-8-BOM")

cst.df$Developed = as.factor(cst.df$Developed) 

#Import cleaned scaled 


#import cleaned

#Must omit values before running model
cst.df <- na.omit(cst.df)
```

```{r train test split}
#Train / Test split by Year
cst.training <- cst.df[c(cst.df$Year <= 2010),]
cst.test <- cst.df[c(cst.df$Year > 2010),]

dim(cst.df)
dim(cst.training)
dim(cst.test)

cst.training <- subset(cst.training, select = -c(Country,Year))
cst.test <- subset(cst.test, select = -c(Country, Year))
```

Variable Selection
Elastic Net Model with 10 Fold Cross Validation
```{r}
library(glmnet)
fitControl<-trainControl(method="repeatedcv",number=10,repeats=10)
# fitControl<-trainControl(method="none")

#GLM Net Model (selecting tuning parameters alpha and lambda via 10 FOLD CV)
# set.seed(1234)
cst.glmnet.fit<-train(Life.expectancy~.,
               data=cst.training,
               method="glmnet",
               trControl = fitControl,
               na.action = na.omit
               )
#glmnet.fit results
cst.glmnet.fit
#Model Coefficients
coef(cst.glmnet.fit$finalModel,cst.glmnet.fit$finalModel$lambdaOpt)
```

```{r}
#Creating using the test set. Resulting in the RMSE of the validation set
cst.glmnet.pred<-predict(cst.glmnet.fit, newdata = cst.test[,-1], observed = cst.test[,1])
RMSE(cst.glmnet.pred, cst.test$Life.expectancy)

#RMSE
glmnet.RMSE<-sqrt(mean((cst.test$Life.expectancy-glmnet.pred)^2))
glmnet.RMSE
plot(cst.glmnet.pred, cst.test$Life.expectancy, ylim=c(40,100), xlim=c(40,100))
lines(0:100,0:100)


#Here is a more natural tool to compute RMSE as well as some additional metrics
cst.glmnet.resamp<-postResample(pred = cst.glmnet.pred, obs = cst.test$Life.expectancy)
cst.glmnet.resamp

#Ranking of the predictors
list(varImp(cst.glmnet.fit))
plot(varImp(cst.glmnet.fit))
# Top 5 in order of importance features selected by the Elastic Net Model
#  (filtered.Income.composition.of.resources,log.adj.Adult.Mortality, Developed, log.EstGDPpercapita,log.HIV.AIDS)

```

Variable Selection - Lasso

```{r}
X <- model.matrix(Life.expectancy~.,cst.training)[,-1]

y <- cst.training$Life.expectancy

xTest <- model.matrix(Life.expectancy~.,cst.test)[,-1]

yTest <- cst.test$Life.expectancy

lambdaGrid = 10^seq(10,-2, length =100)

cst.Lasso<-train(y = y,
             x = X,
             method = 'glmnet',
             tuneGrid = expand.grid(alpha = 1, lambda = lambdaGrid),
             na.action = na.omit
             )

cst.Lasso.pred <- cst.Lasso %>% predict(xTest)

cst.Lasso_RMSE = RMSE(cst.Lasso.pred, yTest)
cst.Lasso_RMSE

Lasso.test <-postResample(pred = cst.Lasso.pred, obs = cst.test$Life.expectancy)
Lasso.test

coef(cst.Lasso$finalMode,cst.Lasso$finalModel$lambdaOpt)

varImp(cst.Lasso)
plot(varImp(cst.Lasso))
# 
# Top 5 in order of importance features selected by of Lasso
#  (filtered.Income.composition.of.resources,log.adj.Adult.Mortality, Developed, log.EstGDPpercapita,log.HIV.AIDS)
# Selected the same variables as Elastic Net

```

Variable Selection with Ridge
```{r}
#Recheck RMSE for Ridge and Lasso. getting the same values.
cst.Ridge <-train(y = y, 
              x = X,
              method = 'glmnet',
              tuneGrid = expand.grid(alpha = 0, lambda = lambdaGrid),
              na.action = na.omit
              )
cst.Ridge.pred <- cst.Lasso %>% predict(xTest)

cst.Ridge_RMSE = RMSE(cst.Ridge.pred, yTest)
cst.Ridge_RMSE

Ridge.test<-postResample(pred = cst.Ridge.pred, obs = cst.test$Life.expectancy)
Ridge.test

coef(cst.Ridge$finalModel,cst.Ridge$finalModel$lambdaOpt)

varImp(cst.Ridge)
plot(varImp(cst.Ridge))
# Top 4 in order of importance features selected by of Ridge
#  (filtered.Income.composition.of.resources,log.adj.Adult.Mortality,log.HIV.AIDS, Developed)
# Selected the same variables as Ridge

```




Variable Selection - Forward
```{r}
#get coef for forward selection
fitControlForward<-trainControl(method="cv")

cst.f.fit<-train(x=X,
             y=y,
             method="leapForward",
             trControl=fitControlForward,
             tuneGrid = expand.grid(nvmax = seq(1, 12, 1))
             )
cst.f.fit
plot(cst.f.fit)
varImp(cst.f.fit,)
plot(varImp(cst.f.fit))

coef(cst.f.fit$finalModel, cst.f.fit$finalModel$last)
coef(cst.f.fit$finalModel)

#Top  in order of importance features selected by Forward Selection
#  (filtered.Income.composition.of.resources,log.adj.Adult.Mortality,log.HIV.AIDS, Developed)
#Selected the same variables as Forward Selection

```

Top 5 in order of importance features selected by the Elastic Net Model
 (filtered.Income.composition.of.resources,log.adj.Adult.Mortality, Developed, log.EstGDPpercapita,log.HIV.AIDS)
 
Top 5 in order of importance features selected by of Lasso
 (filtered.Income.composition.of.resources,log.adj.Adult.Mortality, Developed, log.EstGDPpercapita,log.HIV.AIDS)
Selected the same variables as Elastic Net

Top 4 in order of importance features selected by Ridge
 (filtered.Income.composition.of.resources,log.adj.Adult.Mortality,log.HIV.AIDS, Developed)
Selected the same variables as Ridge)
(Left out log.EstGDPpercapita)

Moving Forward from variable selection. Now we will check our models using LM with variables selected by Lasso, Elastic Net, and Ridge.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                                 Model Metrics
                               AIC BIC RMSE MSE
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


```{r AIC BIC RMSE, MSE functions}
AIC <- function(y, y_pred, n, k){
  resids = y - y_pred
  sse = sum(resids^2)
  AIC =  n * log(sse/n) + 2*(k + 1)
  print(return(AIC))
}

BIC <- function(y, y_pred, n, k){
  resids = y - y_pred
  sse = sum(resids^2)
  BIC = n * log(sse/n) + log(n) * (k+1)
  print(return(BIC))
}

calc.rmse <- function(actual, predicted){
  sqrt(mean(actual - predicted)^2)
}

#create function for MSE / ASE
calc.ase <- function(actual, predicted){
  (mean(actual - predicted)^2)
}

```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                             Step 3.1: Experimental Model Engine
                                       Knn Regression
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r knn regression with caret}
library(caret)
library(plyr)
library(lattice)

knn2 <- knnreg(cst.training$Life.expectancy ~ ., data = cst.training, k=2)

train.knn = function(mr.rogers){
  knnreg(cst.training$Life.expectancy ~., data = cst.training, k=mr.rogers)
} 

test.knn =  function(mr.rogers){
  knnreg(cs.test$Life.expectancy ~., data = cs.testing.data, k=mr.rogers)
} 

k.to.try <- seq(1,50, by = 1)
#create and store list knn predictions for k = 1 thru fiddy
knn.list.train = lapply(k.to.try, train.knn)
knn.list.test = lapply(k.to.try, test.knn)


#create and store list of predictions
knn.train.predictions <- lapply(knn.list.train, predict, cst.training)
knn.test.predictions <- lapply(knn.list.test, predict, cs.testing.data)
```

