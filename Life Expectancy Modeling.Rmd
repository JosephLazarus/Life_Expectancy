---
title: "Life Expectancy Modeling"
author: "Satvik, Joe, and Rick"
output: html_notebook
editor_options: 
  chunk_output_type: console
---
```{r}
library(ggthemes)
theme_set(theme_fivethirtyeight())
theme_update(axis.title = element_text()) #the default for fivethirtyeight is to not show axis labels, this removes that default so we can choose to specify and display axis titles
theme_update(plot.title = element_text(hjust = 0.5))
```

```{r import data}
#Import Clean, Scaled, and Transformed CSV 
# cst = cleaned scaled transformed
cst.df <- read.csv("https://raw.githubusercontent.com/JosephLazarus/Life_Expectancy/main/Data_Folder/clean_scaled.csv", header = TRUE, fileEncoding="UTF-8-BOM")

cst.df$Developed = as.factor(cst.df$Developed) 

#Import cleaned scaled 


#import cleaned

#Must omit values before running model
cst.df <- na.omit(cst.df)
```

```{r train test split}
#Train / Test split by Year
cst.training <- cst.df[c(cst.df$Year <= 2010),]
cst.test <- cst.df[c(cst.df$Year > 2010),]

dim(cst.df)
dim(cst.training)
dim(cst.test)

cst.training <- subset(cst.training, select = -c(Country,Year))
cst.test <- subset(cst.test, select = -c(Country, Year))
```

Variable Selection
Elastic Net Model with 10 Fold Cross Validation
```{r}
library(glmnet)
fitControl<-trainControl(method="repeatedcv",number=10,repeats=10)
# fitControl<-trainControl(method="none")

#GLM Net Model (selecting tuning parameters alpha and lambda via 10 FOLD CV)
# set.seed(1234)
cst.glmnet.fit<-train(Life.expectancy~.,
               data=cst.training,
               method="glmnet",
               trControl = fitControl,
               na.action = na.omit
               )
#glmnet.fit results
cst.glmnet.fit
#Model Coefficients
coef(cst.glmnet.fit$finalModel,cst.glmnet.fit$finalModel$lambdaOpt)
```

```{r}
#Creating using the test set. Resulting in the RMSE of the validation set
cst.glmnet.pred<-predict(cst.glmnet.fit, newdata = cst.test[,-1], observed = cst.test[,1])
RMSE(cst.glmnet.pred, cst.test$Life.expectancy)

#RMSE
glmnet.RMSE<-sqrt(mean((cst.test$Life.expectancy-glmnet.pred)^2))
glmnet.RMSE
plot(cst.glmnet.pred, cst.test$Life.expectancy, ylim=c(40,100), xlim=c(40,100))
lines(0:100,0:100)


#Here is a more natural tool to compute RMSE as well as some additional metrics
cst.glmnet.resamp<-postResample(pred = cst.glmnet.pred, obs = cst.test$Life.expectancy)
cst.glmnet.resamp

#Ranking of the predictors
list(varImp(cst.glmnet.fit))
plot(varImp(cst.glmnet.fit))
#Top 6 in order of importance features selected by of Elastic Net Model
#  (filtered.Income.composition.of.resources,log.adj.Adult.Mortality, Developed, log.EstGDPpercapita,log.HIV.AIDS)


```



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                                 Model Metrics
                               AIC BIC RMSE MSE
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


```{r AIC BIC RMSE, MSE functions}
AIC <- function(y, y_pred, n, k){
  resids = y - y_pred
  sse = sum(resids^2)
  AIC =  n * log(sse/n) + 2*(k + 1)
  print(return(AIC))
}

BIC <- function(y, y_pred, n, k){
  resids = y - y_pred
  sse = sum(resids^2)
  BIC = n * log(sse/n) + log(n) * (k+1)
  print(return(BIC))
}

calc.rmse <- function(actual, predicted){
  sqrt(mean(actual - predicted)^2)
}

#create function for MSE / ASE
calc.ase <- function(actual, predicted){
  (mean(actual - predicted)^2)
}

```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                             Step 3.1: Experimental Model Engine
                                       Knn Regression
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r knn regression with caret}
library(caret)
library(plyr)
library(lattice)

knn2 <- knnreg(cst.training$Life.expectancy ~ ., data = cst.training, k=2)

train.knn = function(mr.rogers){
  knnreg(cst.training$Life.expectancy ~., data = cst.training, k=mr.rogers)
} 

test.knn =  function(mr.rogers){
  knnreg(cs.test$Life.expectancy ~., data = cs.testing.data, k=mr.rogers)
} 

k.to.try <- seq(1,50, by = 1)
#create and store list knn predictions for k = 1 thru fiddy
knn.list.train = lapply(k.to.try, train.knn)
knn.list.test = lapply(k.to.try, test.knn)


#create and store list of predictions
knn.train.predictions <- lapply(knn.list.train, predict, cst.training)
knn.test.predictions <- lapply(knn.list.test, predict, cs.testing.data)
```

